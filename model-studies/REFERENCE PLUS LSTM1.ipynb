{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64e4132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyhht.emd import EMD\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Conv1D, Flatten, Dense, Attention\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Read the data from CSV file\n",
    "data = pd.read_csv(\"Office_Garman.csv\", index_col=\"timestamp\", parse_dates=True)\n",
    "\n",
    "# Remove duplicate entries\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "# Set the frequency to hourly\n",
    "data = data.asfreq('H')\n",
    "\n",
    "# Fill missing values using forward fill method\n",
    "data = data.fillna(method='ffill')\n",
    "\n",
    "# Z-score normalization\n",
    "scaler = StandardScaler()\n",
    "normalized_data = scaler.fit_transform(data.values)\n",
    "\n",
    "# Perform CEEMDAN decomposition on the data\n",
    "emd = EMD()\n",
    "imfs = emd(normalized_data[:, 0])  # Replace 0 with the appropriate column index for decomposition\n",
    "\n",
    "# Plot the decomposed waveform and Fuzzy Entropy of each IMF component\n",
    "fig, axs = plt.subplots(len(imfs)+1, figsize=(10, 12))\n",
    "axs[0].plot(normalized_data[:, 0], label='Original Data')\n",
    "axs[0].set_ylabel('Amplitude')\n",
    "axs[0].set_title('Decomposed Waveform')\n",
    "for i, imf in enumerate(imfs):\n",
    "    axs[i+1].plot(imf, label=f'IMF {i+1}')\n",
    "    axs[i+1].set_ylabel('Amplitude')\n",
    "    axs[i+1].set_title(f'IMF {i+1} Fuzzy Entropy')\n",
    "axs[-1].set_xlabel('Time')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Cluster the IMFs using DBSCAN\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "clusters = dbscan.fit_predict(imfs.T)\n",
    "\n",
    "# Plot the effect of DBSCAN clustering\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(imfs[:, 0], imfs[:, 1], c=clusters)\n",
    "plt.xlabel('IMF 1')\n",
    "plt.ylabel('IMF 2')\n",
    "plt.title('DBSCAN Clustering Effect')\n",
    "plt.show()\n",
    "\n",
    "# Predict high-frequency components using Random Forest (RF)\n",
    "rf_model = RandomForestRegressor()\n",
    "rf_model.fit(imfs[:, :n], imfs[:, n])  # Replace n with the appropriate column index of high-frequency components\n",
    "train_rf_pred = rf_model.predict(imfs[:, :n])\n",
    "\n",
    "# Predict low-frequency components using LSTM and self-attention\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(m, 1)))  # Replace m with the appropriate window size\n",
    "lstm_model.add(LSTM(units=128, return_sequences=True))\n",
    "lstm_model.add(Attention())\n",
    "lstm_model.add(Flatten())\n",
    "lstm_model.add(Dense(units=1))\n",
    "lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "lstm_model.fit(imfs[:, n:], imfs[:, :n], epochs=10, batch_size=32)\n",
    "train_lstm_pred = lstm_model.predict(imfs[:, n:])\n",
    "\n",
    "# Combine predictions from RF and LSTM models\n",
    "train_pred = train_rf_pred + train_lstm_pred.flatten()\n",
    "\n",
    "# Plot the prediction waveform\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_pred, label='Predicted')\n",
    "plt.plot(imfs[:, 0], label='Actual')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Prediction Waveform')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Calculate RMSE for each IMF component\n",
    "train_rmse = np.sqrt(mean_squared_error(imfs[:, 0], train_pred))\n",
    "\n",
    "# Plot the RMSE for each IMF component\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_rmse, marker='o')\n",
    "plt.xlabel('IMF Component')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('RMSE for Each IMF Component')\n",
    "plt.xticks(np.arange(0, len(imfs)), np.arange(1, len(imfs)+1))\n",
    "plt.show()\n",
    "\n",
    "def calculate_mape(actual, predicted):\n",
    "    return np.mean(np.abs((actual - predicted) / actual)) * 100\n",
    "\n",
    "# Calculate MAPE for each IMF component\n",
    "train_mape = calculate_mape(imfs[:, 0], train_pred)\n",
    "\n",
    "# Plot the MAPE for each IMF component\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_mape, marker='o')\n",
    "plt.xlabel('IMF Component')\n",
    "plt.ylabel('MAPE')\n",
    "plt.title('MAPE for Each IMF Component')\n",
    "plt.xticks(np.arange(0, len(imfs)), np.arange(1, len(imfs)+1))\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Calculate MAE for each IMF component\n",
    "train_mae = mean_absolute_error(imfs[:, 0], train_pred)\n",
    "\n",
    "# Plot the MAE for each IMF component\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_mae, marker='o')\n",
    "plt.xlabel('IMF Component')\n",
    "plt.ylabel('MAE')\n",
    "plt.title('MAE for Each IMF Component')\n",
    "plt.xticks(np.arange(0, len(imfs)), np.arange(1, len(imfs)+1))\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
