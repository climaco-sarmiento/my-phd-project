{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd55738a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Name 'ds' is reserved.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m train\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m column \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m:  \u001b[38;5;66;03m# Exclude the target variable\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m         model\u001b[38;5;241m.\u001b[39madd_regressor(column)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Fit the Prophet model\u001b[39;00m\n\u001b[1;32m     48\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(train)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-UniversidadedoAlgarve/analysis-dir/ts-data/env/lib/python3.11/site-packages/prophet/forecaster.py:631\u001b[0m, in \u001b[0;36mProphet.add_regressor\u001b[0;34m(self, name, prior_scale, standardize, mode)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[1;32m    630\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRegressors must be added prior to model fitting.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_column_name(name, check_regressors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prior_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    633\u001b[0m     prior_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mholidays_prior_scale)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-UniversidadedoAlgarve/analysis-dir/ts-data/env/lib/python3.11/site-packages/prophet/forecaster.py:223\u001b[0m, in \u001b[0;36mProphet.validate_column_name\u001b[0;34m(self, name, check_holidays, check_seasonalities, check_regressors)\u001b[0m\n\u001b[1;32m    220\u001b[0m reserved_names\u001b[38;5;241m.\u001b[39mextend([\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mds\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcap\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloor\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_scaled\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcap_scaled\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m reserved_names:\n\u001b[0;32m--> 223\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName \u001b[39m\u001b[38;5;132;01m{name!r}\u001b[39;00m\u001b[38;5;124m is reserved.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m    225\u001b[0m     )\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (check_holidays \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mholidays \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    227\u001b[0m         name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mholidays[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mholiday\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()):\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    229\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName \u001b[39m\u001b[38;5;132;01m{name!r}\u001b[39;00m\u001b[38;5;124m already used for a holiday.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m    230\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Name 'ds' is reserved."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Import energy data\n",
    "newData = pd.read_csv(\"Office_Garman.csv\", index_col=\"timestamp\", parse_dates=True)\n",
    "newData = newData.drop_duplicates()\n",
    "newData = newData.asfreq('H')\n",
    "newData = newData.fillna(method='ffill')\n",
    "\n",
    "# Import holiday data\n",
    "holidaysdf = pd.read_csv(\"schedule9.csv\", header=None, names=[\"ds\", \"holiday\"])\n",
    "holidaysdf[\"ds\"] = pd.to_datetime(holidaysdf[\"ds\"])\n",
    "holidaysdf[\"holiday\"] = holidaysdf[\"holiday\"].astype(str)\n",
    "\n",
    "# Import weather data\n",
    "weatherdf = pd.read_csv(\"weather5.csv\")\n",
    "weatherdf[\"timestamp\"] = pd.to_datetime(weatherdf[\"timestamp\"])\n",
    "weatherdf = weatherdf.set_index(\"timestamp\")  # Set the index to timestamp\n",
    "\n",
    "# Merge newData and weatherdf\n",
    "merged_data = pd.merge(newData, weatherdf, left_index=True, right_index=True, how='outer')\n",
    "\n",
    "# Merge merged_data and holidaysdf\n",
    "merged_data = pd.merge(merged_data, holidaysdf, left_index=True, right_on='ds', how='left')\n",
    "\n",
    "# Set the index back to DatetimeIndex\n",
    "merged_data.set_index('ds', inplace=True)\n",
    "\n",
    "# Split data into train and test sets\n",
    "split_date = pd.Timestamp('2015-09-30')\n",
    "train = merged_data.loc[merged_data.index <= split_date, [\"Office_Garman\"]]\n",
    "train = train.rename(columns={\"Office_Garman\": \"y\"})\n",
    "train.reset_index(inplace=True)\n",
    "train.rename(columns={\"timestamp\": \"ds\"}, inplace=True)\n",
    "\n",
    "test = merged_data.loc[merged_data.index > split_date]\n",
    "\n",
    "# Prepare the Prophet model\n",
    "model = Prophet()\n",
    "for column in train.columns:\n",
    "    if column != \"y\":  # Exclude the target variable\n",
    "        model.add_regressor(column)\n",
    "\n",
    "# Fit the Prophet model\n",
    "model.fit(train)\n",
    "\n",
    "\n",
    "# Generate predictions\n",
    "future = model.make_future_dataframe(periods=len(test), freq='H')\n",
    "future = pd.merge(future, test.reset_index(), on='ds', how='left')\n",
    "predictions = model.predict(future)\n",
    "\n",
    "# Plot actual data and predictions\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train.index, train[\"Office_Garman\"], label='Train')\n",
    "plt.plot(test.index, test[\"Office_Garman\"], label='Test')\n",
    "plt.plot(predictions[\"ds\"], predictions[\"yhat\"], label='Predictions')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Energy Usage')\n",
    "plt.title('Prophet Model Predictions')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot zoomed-in version\n",
    "zoom_start_date = pd.to_datetime('2015-09-15')\n",
    "zoom_end_date = pd.to_datetime('2015-12-31')\n",
    "zoomed_data = merged_data[(merged_data.index >= zoom_start_date) & (merged_data.index <= zoom_end_date)]\n",
    "\n",
    "zoomed_predictions = predictions[(predictions[\"ds\"] >= zoom_start_date) & (predictions[\"ds\"] <= zoom_end_date)]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(zoomed_data.index, zoomed_data[\"Office_Garman\"], label='Actual Data')\n",
    "plt.plot(zoomed_predictions[\"ds\"], zoomed_predictions[\"yhat\"], label='Predictions')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Energy Usage')\n",
    "plt.title('Zoomed-in Plot: Prophet Model Predictions')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mae = mean_absolute_error(test[\"Office_Garman\"], predictions[\"yhat\"].tail(len(test)))\n",
    "mape = mean_absolute_percentage_error(test[\"Office_Garman\"], predictions[\"yhat\"].tail(len(test)))\n",
    "rmse = np.sqrt(mean_squared_error(test[\"Office_Garman\"], predictions[\"yhat\"].tail(len(test))))\n",
    "\n",
    "\n",
    "print(\"MAE:\", mae)\n",
    "print(\"MAPE:\", mape)\n",
    "print(\"RMSE:\", rmse)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
